{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a85538-8e7e-4771-a5e7-d7b18d3b81bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: setup NoTexBook theme\n",
    "%load_ext notexbook\n",
    "\n",
    "%texify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f5b821",
   "metadata": {},
   "source": [
    "# Model Inversion Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68655027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e011e0-7cd6-4832-a72c-be001f23fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweak to reuse the Python modules defined in previous section\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, os.path.join(os.path.abspath(os.path.curdir), \"..\", \"2-ml-models-attacks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45779d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import ORLFaces\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5132ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is a hack to get around \"User-agent\" limitations when downloading MNIST datasets\n",
    "#       see, https://github.com/pytorch/vision/issues/3497 for more information\n",
    "from six.moves import urllib\n",
    "\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [(\"User-agent\", \"Mozilla/5.0\")]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "DATA_FOLDER = Path(os.path.join(os.path.abspath(os.path.curdir), \"..\")) / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db6abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "orl_faces_train = ORLFaces(\n",
    "    root=DATA_FOLDER, download=True, split=\"train\", transform=ToTensor()\n",
    ")\n",
    "orl_faces_test = ORLFaces(root=DATA_FOLDER, download=True, split=\"test\", transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d51644",
   "metadata": {},
   "outputs": [],
   "source": [
    "orl_faces_train.data.shape, orl_faces_test.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859989b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    orl_faces_train, batch_size=32, shuffle=False, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c16f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction Attack Settings\n",
    "# See Paper, Section 5.2 - Reconstruction Attack\n",
    "α = 5000\n",
    "β = 100\n",
    "γ = 0.99\n",
    "λ = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39426d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import SoftmaxRegression, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34de5f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "CHECKPOINT_FOLDER = Path(\"./checkpoints/\")\n",
    "\n",
    "\n",
    "def load_weights(model, model_name: str = None) -> th.TensorType:\n",
    "    if model_name is None or not model_name:\n",
    "        model_name = model.__class__.__name__.lower()\n",
    "    w_file = CHECKPOINT_FOLDER / f\"{model_name}.pt\"\n",
    "    try:\n",
    "        weights = th.load(open(w_file, \"rb\"))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Model Weights file {w_file} does not exist! Please check.\")\n",
    "        return None\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c65ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_reg = SoftmaxRegression()\n",
    "weights = load_weights(softmax_reg, model_name=\"softmax_reg_opacus_test\")\n",
    "\n",
    "weights[\"regression.weight\"] = weights[\"_module.regression.weight\"]\n",
    "_ = weights.pop(\"_module.regression.weight\")\n",
    "\n",
    "weights[\"regression.bias\"] = weights[\"_module.regression.bias\"]\n",
    "_ = weights.pop(\"_module.regression.bias\")\n",
    "\n",
    "if weights is not None:\n",
    "    softmax_reg.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e83c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(im_flatten):\n",
    "    max_v = th.max(im_flatten)\n",
    "    min_v = th.min(im_flatten)\n",
    "    return (im_flatten - min_v) / (max_v - min_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52a0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mi_face(model, target_label):\n",
    "    aim_tensor = th.zeros(1, 112 * 92)\n",
    "    aim_tensor.requires_grad = True\n",
    "\n",
    "    lossn_1 = 10\n",
    "    b = 0\n",
    "    g = 0\n",
    "\n",
    "    out = model(aim_tensor.detach())\n",
    "    _, pred = th.max(out, 1)\n",
    "    print(pred)\n",
    "    print(f\"original input image {target_label}\")\n",
    "    plt.imshow(\n",
    "        np.transpose(aim_tensor.detach().reshape(1, 112, 92).numpy(), (1, 2, 0)),\n",
    "        cmap=\"Greys\",\n",
    "    )\n",
    "    plt.show()\n",
    "    print(\n",
    "        f\"original input image predict label {target_label} - predict label: {pred.item()}\"\n",
    "    )\n",
    "\n",
    "    criterion = th.nn.NLLLoss()\n",
    "\n",
    "    for i in range(α):\n",
    "        out = model(aim_tensor)\n",
    "        if aim_tensor.grad is not None:\n",
    "            aim_tensor.grad.zero_()\n",
    "        out = out.reshape(1, 40)\n",
    "        target_class = th.tensor([target_label])\n",
    "        loss = criterion(out, target_class)\n",
    "        loss.backward()\n",
    "        aim_grad = aim_tensor.grad\n",
    "\n",
    "        # SGD Step\n",
    "        # see https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD\n",
    "        aim_tensor = aim_tensor - (λ * aim_grad)\n",
    "        aim_tensor = process(aim_tensor)\n",
    "        aim_tensor = th.clamp(aim_tensor.detach(), 0, 1)\n",
    "        aim_tensor.requires_grad = True\n",
    "        if loss >= lossn_1:\n",
    "            b += 1\n",
    "            if b > β:\n",
    "                break\n",
    "        else:\n",
    "            b = 0\n",
    "        lossn_1 = loss\n",
    "        if loss < γ:\n",
    "            break\n",
    "\n",
    "    print(f\"Attack completed at {i} iterations\")\n",
    "    out = model(aim_tensor.detach())\n",
    "    _, pred = th.max(out, 1)\n",
    "    print(pred)\n",
    "    print(f\"inverted image {target_label}\")\n",
    "    plt.imshow(\n",
    "        np.transpose(aim_tensor.detach().reshape(1, 112, 92).numpy() * 255, (1, 2, 0)),\n",
    "        cmap=\"Greys\",\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44013f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in range(10):\n",
    "    mi_face(softmax_reg, cl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

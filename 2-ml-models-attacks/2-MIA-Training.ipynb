{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e39d12-6b19-451d-b1b9-2502d6f8e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: setup NoTexBook theme\n",
    "%load_ext notexbook\n",
    "\n",
    "%texify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd69b34",
   "metadata": {},
   "source": [
    "# Model Inversion Attack - Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed1933",
   "metadata": {},
   "source": [
    "In this notebook we will be performing the training of **two** (out of three) of the ML models considered in the paper:\n",
    "\n",
    "> **Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures**, by _Fredrikson, et. al_, 2015 \n",
    "[DOI](https://dl.acm.org/doi/pdf/10.1145/2810103.2813677).\n",
    "\n",
    "The two models are `SoftmaxRegression` and `MLP`.\n",
    "\n",
    "‚ö†Ô∏è **NOTE**: Please feel free to skip this notebook completely (if you don't want to **re-train** the models on your own) and jump directly to the next [MIA Reconstruction](./2-MIA-Reconstruction.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee64647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3126b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is a hack to get around \"User-agent\" limitations when downloading MNIST datasets\n",
    "#       see, https://github.com/pytorch/vision/issues/3497 for more information\n",
    "from six.moves import urllib\n",
    "\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [(\"User-agent\", \"Mozilla/5.0\")]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9086c266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import ORLFaces\n",
    "from torchvision.transforms import ToTensor, Grayscale, Compose\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc48ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility Settings\n",
    "\n",
    "SEED = 123456\n",
    "\n",
    "np.random.seed(SEED)\n",
    "th.manual_seed(SEED)\n",
    "if th.cuda.is_available():\n",
    "    th.cuda.manual_seed_all(SEED)\n",
    "    th.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc0251e",
   "metadata": {},
   "source": [
    "### The `ORLFaces` Dataset\n",
    "\n",
    "The original paper considers the **AT&T Face Database** faces dataset (which I have encapsualted and made available as a PyTorch `Dataset`): `ORLFaces`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e23a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "DATA_FOLDER = Path(os.path.join(os.path.abspath(os.path.curdir), \"..\")) / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee5718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16625ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_trasform = Compose([Grayscale(num_output_channels=1), ToTensor()])\n",
    "\n",
    "orl_faces_train = ORLFaces(\n",
    "    root=DATA_FOLDER, download=True, split=\"train\", transform=imgs_trasform\n",
    ")\n",
    "orl_faces_test = ORLFaces(\n",
    "    root=DATA_FOLDER, download=True, split=\"test\", transform=imgs_trasform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ae6a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    orl_faces_train, batch_size=BATCH_SIZE, shuffle=True, drop_last=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    orl_faces_test, batch_size=BATCH_SIZE, shuffle=False, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2b2a27",
   "metadata": {},
   "source": [
    "#### A few notes about the dataset \n",
    "\n",
    "The `ORLFaces` dataset contains `400` image files corresponding to `40` different subjects (`10` photo each).\n",
    "\n",
    "\n",
    "Images are `112x92` pixels, with `256` grey levels per pixel, and (originally) stored in `PGM` format.\n",
    "The photos of the subjects have been taken at different times, are varying the lightning, the facial expressions\n",
    "    (e.g. open/closed eyes, smiling/serious face), and the facial details.\n",
    "\n",
    "**Train/Test** partitions have been generated similarly to what has been done in the original paper, that is: \n",
    "\n",
    "(for each subject):\n",
    "\n",
    "- Randomly pick $7$ (out of $10$) images of the subject and add them to the **training set**\n",
    "- Add remaining $3$ images to the **test set**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425c305c",
   "metadata": {},
   "source": [
    "#### Visualise a few Samples in the Dataset\n",
    "\n",
    "Before we start with the training, let's visualise a few random samples extracted from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e794b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(10, 12))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa210aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "images, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089395c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc07e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images\n",
    "imshow(make_grid(images))\n",
    "# print labels\n",
    "print(\" \".join(f\"{labels[j]}\" for j in range(BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2513010f",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è **Note**: Do you see the **exact same faces** that are being displayed here? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7b9841",
   "metadata": {},
   "source": [
    "## Machine Learning Model Training\n",
    "\n",
    "In the original Paper, authors refer to three separated models used as reference examples for the Model Inversion Attack. \n",
    "\n",
    "Here to keep things simple, we will only consider two of them: `SoftmaxRegression` and `MLP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d1c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import SoftmaxRegression, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14bbfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a193ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Œª = 0.1  # optimiser learning rate, as used in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d5e71",
   "metadata": {},
   "source": [
    "#### Training `SoftmaxRegression`\n",
    "\n",
    "Note: This should be super-fast even on a laptop (small model, small data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_reg = SoftmaxRegression()\n",
    "softmax_sgd = th.optim.SGD(softmax_reg.parameters(), lr=Œª)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb471d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e0f0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    model=softmax_reg,\n",
    "    optimiser=softmax_sgd,\n",
    "    loaders=(train_loader, test_loader),\n",
    "    model_name=\"softmax_mia\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8acf454",
   "metadata": {},
   "source": [
    "### Training `MLP`\n",
    "\n",
    "‚ö†Ô∏è **Note**:  This may be a bit slower to train on a laptop (it shouldn't be that much, though!) \n",
    "\n",
    "If you notice that it is the case, please also feel free to skip this and jump at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c1109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "mlp_sgd = th.optim.SGD(mlp.parameters(), lr=Œª)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e40c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b3abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    model=mlp,\n",
    "    optimiser=mlp_sgd,\n",
    "    loaders=(train_loader, test_loader),\n",
    "    model_name=\"mlp_mia\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5646846",
   "metadata": {},
   "source": [
    "### Congratulations\n",
    "\n",
    "**Well done** üéâ\n",
    "\n",
    "Now that we have our two reference **trained** model, we are ready to setup and launch the _model inversion_ attack to the model. \n",
    "\n",
    "$\\rightarrow$ **MIA Reconstruction**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

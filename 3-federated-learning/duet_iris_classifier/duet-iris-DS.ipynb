{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdb755e-d4c9-4652-93ae-e7f0b7ef2a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "##! IGNORE THIS if running on Google Colab\n",
    "%load_ext notexbook\n",
    "\n",
    "%texify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5c8cc8-0fc5-493d-b824-f3e7a2712c1a",
   "metadata": {},
   "source": [
    "<img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\" width=\"5%\" class=\"badges\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41719a3e-e4ce-4982-9279-c52d40eca45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT THIS ONLY if running on Google Colab\n",
    "\n",
    "# !pip install syft==0.5.1\n",
    "# !pip install protobuf==3.20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e298ae2",
   "metadata": {},
   "source": [
    "**ORIGINAL NOTEBOOK** [here](https://github.com/OpenMined/courses/tree/foundations-of-private-computation/federated-learning/duet_iris_classifier) from the PrivateAI Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-crisis",
   "metadata": {},
   "source": [
    "## Part 1: Join the Duet Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "\n",
    "SERVER_ID = \"\" # paste server ID here\n",
    "\n",
    "duet = sy.duet(SERVER_ID)\n",
    "# Option to replace with the following if RUNNING locally\n",
    "# duet = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-beast",
   "metadata": {},
   "source": [
    "#### <img src=\"https://github.com/OpenMined/design-assets/raw/master/logos/OM/mark-primary-light.png\" alt=\"he-black-box\" width=\"5%\" class=\"maxw5\"/> Now STOP & Run the Data Owner notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-suffering",
   "metadata": {},
   "source": [
    "## Part 2: Search for Available Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data scientist can check the list of searchable data in Data Owner's duet store\n",
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-cutting",
   "metadata": {},
   "source": [
    "Data Scientist wants to use the iris dataset. (S)He needs a pointer to the data and\n",
    "a pointer to the target for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ptr = duet.store[\"iris-data\"]\n",
    "target_ptr = duet.store[\"iris-target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-interaction",
   "metadata": {},
   "source": [
    "`data_ptr` is a reference to the iris dataset remotely available on data owner's server.\n",
    "\n",
    "`target_ptr` is a reference to the iris dataset LABELS remotely available on data owner's server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_ptr)\n",
    "print(target_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-english",
   "metadata": {},
   "source": [
    "## Part 3: Perform Logistic Regression on Iris dataset\n",
    "Now the data scientist can perform machine learning on the data that is in the Data Owner's duet server, without the owner having to share his/her data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-dominican",
   "metadata": {},
   "source": [
    "#### Basic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-symphony",
   "metadata": {},
   "source": [
    "First the data scientist needs to know some basic information about the dataset.\n",
    "1. The length of the dataset\n",
    "2. The input dimension\n",
    "3. The output dimension\n",
    "\n",
    "These information have to be explicitly shared by the Data Owner. Let's try to find them in the data description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(duet.store.pandas[\"Description\"][0])\n",
    "print()\n",
    "print(duet.store.pandas[\"Description\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-destruction",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 4\n",
    "out_dim = 3\n",
    "n_samples = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-belgium",
   "metadata": {},
   "source": [
    "First, let's create our model for `Logistic Regression`. \n",
    "\n",
    "The model will be a `SyNet` - which is very similar to a standard `torch.nn.Module`.\n",
    "\n",
    "- The main difference is that here we inherit from `sy.Module` instead of `nn.Module`. \n",
    "- We also need to pass in a variable called `torch_ref` which we will use internally for any calls that you would normally make to `torch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "        self.layer1 = self.torch_ref.nn.Linear(in_dim, 20)\n",
    "        self.layer2 = self.torch_ref.nn.Linear(20, 30)\n",
    "        self.out = self.torch_ref.nn.Linear(30, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.torch_ref.nn.functional.relu(self.layer1(x))\n",
    "        x = self.torch_ref.nn.functional.relu(self.layer2(x))\n",
    "        output = self.torch_ref.nn.functional.log_softmax(self.out(x), dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-macro",
   "metadata": {},
   "source": [
    "Now we can create a local model by passing our local copy of torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-surge",
   "metadata": {},
   "source": [
    "Now we will send the local copy of the model to our partner's duet server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model = local_model.send(duet)  # send the model to the Data Owner for Remote Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-calgary",
   "metadata": {},
   "source": [
    "Let's create an alias for our partnerâ€™s torch called `remote_torch` so we can refer to the local torch as `torch` and any operation we want to do remotely as `remote_torch`. \n",
    "\n",
    "Remember, the return values from `remote_torch` are **Pointers**, not the real objects. \n",
    "\n",
    "They mostly act the same when using them with other Pointers but they cannot be mixed with local torch objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch = duet.torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-samba",
   "metadata": {},
   "source": [
    "We will get a pointer to our remote model parameters. \n",
    "\n",
    "Then we will set our optimizer. \n",
    "\n",
    "Here, we will be using `Adam optimizer`:\n",
    "- `params` is a pointer to the list of parameters. \n",
    "- `optim` is a reference to the Adam optimizer which can be used to optimize the remote model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = remote_model.parameters()\n",
    "optim = remote_torch.optim.Adam(params=params, lr=0.01)\n",
    "print(\"params:\", params)\n",
    "print(\"optim:\", optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-acoustic",
   "metadata": {},
   "source": [
    "Now we will create our `train` function. \n",
    "\n",
    "It will take few parameters, like the `remote_model`, `torch_ref`, `optim` and `data_ptr` and `target_ptr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train(iterations, model, torch_ref, optim, data_ptr, target_ptr):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in tqdm(range(iterations), desc=\"Epochs: \"):\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        output = model(data_ptr)\n",
    "\n",
    "        # nll_loss = negative log-liklihood loss\n",
    "        loss = torch_ref.nn.functional.nll_loss(output, target_ptr.long())\n",
    "\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        loss_value = loss_item.get(\n",
    "            reason=\"To evaluate training progress\", request_block=True, timeout_secs=5\n",
    "        )\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch\", i, \"loss\", loss_value)\n",
    "\n",
    "        losses.append(loss_value)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-international",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iteration = 50\n",
    "losses = train(iteration, remote_model, remote_torch, optim, data_ptr, target_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(iteration), losses)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"iteration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-judge",
   "metadata": {},
   "source": [
    "### Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_model(model):\n",
    "    if not model.is_local:\n",
    "        local_model = model.get(\n",
    "            request_block=True,\n",
    "            reason=\"To run test and inference locally\",\n",
    "            timeout_secs=5,\n",
    "        )\n",
    "    else:\n",
    "        local_model = model\n",
    "\n",
    "    return local_model\n",
    "\n",
    "\n",
    "local_model = get_local_model(remote_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-amateur",
   "metadata": {},
   "source": [
    "### Test on local data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d6b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 12345\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "_, X_test, _, y_test = train_test_split(X, y, random_state=SEED, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.FloatTensor(np.array(X_test))\n",
    "y_test = torch.LongTensor(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-waste",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_test)):\n",
    "        sample = X_test[i]\n",
    "        y_hat = local_model(sample.unsqueeze(0))\n",
    "        pred = y_hat.argmax().item()\n",
    "        print(f\"Prediction: {pred} Ground Truth: {y_test[i]}\")\n",
    "        preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, preds)\n",
    "print(\"Overall test accuracy\", acc * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
